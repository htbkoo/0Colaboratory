{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.fury.io/zchcRumz4r8ovaFYUPon/cloverhealth/\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.0-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.5 MB 11.4 MB/s eta 0:00:01    |█████                           | 50.8 MB 11.2 MB/s eta 0:00:25     |███████                         | 69.9 MB 8.7 MB/s eta 0:00:29     |███████████████████████▊        | 237.7 MB 14.8 MB/s eta 0:00:06\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.13.0-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 613 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.31.0-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Using cached wheel-0.35.1-py2.py3-none-any.whl (33 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 937 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 7.9 MB/s eta 0:00:012\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 704 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (47.1.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.21.1-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 516 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Using legacy setup.py install for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for wrapt, since package 'wheel' is not installed.\n",
      "Installing collected packages: protobuf, wheel, astunparse, numpy, keras-preprocessing, oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, markdown, absl-py, tensorboard-plugin-wit, werkzeug, grpcio, tensorboard, termcolor, opt-einsum, h5py, tensorflow-estimator, gast, wrapt, scipy, google-pasta, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.21.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.35.1 wrapt-1.12.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_gpu_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.6.0-cp38-cp38-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 79 kB/s s eta 0:00:01   |▉                               | 20.0 MB 1.6 MB/s eta 0:07:32     |█▎                              | 30.7 MB 9.3 MB/s eta 0:01:17     |█▍                              | 32.6 MB 9.3 MB/s eta 0:01:17     |███▉                            | 89.7 MB 4.8 MB/s eta 0:02:18     |██████                          | 138.7 MB 3.8 MB/s eta 0:02:41     |██████████▌                     | 246.0 MB 4.4 MB/s eta 0:01:55     |██████████████▊                 | 344.3 MB 7.2 MB/s eta 0:00:57     |██████████████▉                 | 347.1 MB 7.2 MB/s eta 0:00:56     |█████████████████▍              | 407.2 MB 15.5 MB/s eta 0:00:23     |██████████████████▋             | 434.3 MB 1.6 MB/s eta 0:03:20     |████████████████████            | 466.7 MB 8.6 MB/s eta 0:00:33     |████████████████████▉           | 486.9 MB 13.0 MB/s eta 0:00:21     |██████████████████████▎         | 520.7 MB 9.1 MB/s eta 0:00:25     |██████████████████████▋         | 529.4 MB 19.5 MB/s eta 0:00:12     |████████████████████████▌       | 573.5 MB 42.7 MB/s eta 0:00:05     |█████████████████████████       | 583.3 MB 24.8 MB/s eta 0:00:07     |█████████████████████████▍      | 593.7 MB 18.0 MB/s eta 0:00:09     |███████████████████████████▊    | 649.3 MB 23.5 MB/s eta 0:00:05     |████████████████████████████▏   | 659.7 MB 17.8 MB/s eta 0:00:06     |████████████████████████████▋   | 668.2 MB 17.8 MB/s eta 0:00:05     |████████████████████████████▋   | 669.3 MB 17.8 MB/s eta 0:00:05     |██████████████████████████████▏ | 707.0 MB 20.7 MB/s eta 0:00:03     |██████████████████████████████▉ | 720.3 MB 12.7 MB/s eta 0:00:03     |███████████████████████████████ | 726.4 MB 13.2 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.7.0-cp38-cp38-manylinux1_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/lib/python3.8/site-packages (from torchvision) (7.2.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=aec75a92f9a16453148ad0e2e17628d316ec8ff854968d603080dad5c002fa50\n",
      "  Stored in directory: /home/hey/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: future, torch, torchvision\n",
      "Successfully installed future-0.18.2 torch-1.6.0 torchvision-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/hey/.pyenv/versions/3.8.5/envs/self_jupyter_notebooks/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4881, 0.7684, 0.1477],\n",
      "        [0.6722, 0.6547, 0.6031],\n",
      "        [0.0559, 0.7414, 0.6955],\n",
      "        [0.3350, 0.0434, 0.0156],\n",
      "        [0.7453, 0.3163, 0.1239]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(a, 1, out=a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7fd14098e7f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2060 SUPER'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 1.5 MB\n",
      "Cached:    2048.0 MB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024,1), 'MB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024,1), 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0894, 0.9722, 0.1894, 0.7359, 0.0097, 0.2451, 0.1773, 0.8162, 0.2241,\n",
       "        0.0305], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3061, 0.3002, 0.0928, 0.4943, 0.1036, 0.2409, 0.0161, 0.9883, 0.3594,\n",
       "        0.0591], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('active.all.allocated', 60),\n",
       "             ('active.all.current', 3),\n",
       "             ('active.all.freed', 57),\n",
       "             ('active.all.peak', 9),\n",
       "             ('active.large_pool.allocated', 0),\n",
       "             ('active.large_pool.current', 0),\n",
       "             ('active.large_pool.freed', 0),\n",
       "             ('active.large_pool.peak', 0),\n",
       "             ('active.small_pool.allocated', 60),\n",
       "             ('active.small_pool.current', 3),\n",
       "             ('active.small_pool.freed', 57),\n",
       "             ('active.small_pool.peak', 9),\n",
       "             ('active_bytes.all.allocated', 33792),\n",
       "             ('active_bytes.all.current', 1536),\n",
       "             ('active_bytes.all.freed', 32256),\n",
       "             ('active_bytes.all.peak', 4608),\n",
       "             ('active_bytes.large_pool.allocated', 0),\n",
       "             ('active_bytes.large_pool.current', 0),\n",
       "             ('active_bytes.large_pool.freed', 0),\n",
       "             ('active_bytes.large_pool.peak', 0),\n",
       "             ('active_bytes.small_pool.allocated', 33792),\n",
       "             ('active_bytes.small_pool.current', 1536),\n",
       "             ('active_bytes.small_pool.freed', 32256),\n",
       "             ('active_bytes.small_pool.peak', 4608),\n",
       "             ('allocated_bytes.all.allocated', 33792),\n",
       "             ('allocated_bytes.all.current', 1536),\n",
       "             ('allocated_bytes.all.freed', 32256),\n",
       "             ('allocated_bytes.all.peak', 4608),\n",
       "             ('allocated_bytes.large_pool.allocated', 0),\n",
       "             ('allocated_bytes.large_pool.current', 0),\n",
       "             ('allocated_bytes.large_pool.freed', 0),\n",
       "             ('allocated_bytes.large_pool.peak', 0),\n",
       "             ('allocated_bytes.small_pool.allocated', 33792),\n",
       "             ('allocated_bytes.small_pool.current', 1536),\n",
       "             ('allocated_bytes.small_pool.freed', 32256),\n",
       "             ('allocated_bytes.small_pool.peak', 4608),\n",
       "             ('allocation.all.allocated', 60),\n",
       "             ('allocation.all.current', 3),\n",
       "             ('allocation.all.freed', 57),\n",
       "             ('allocation.all.peak', 9),\n",
       "             ('allocation.large_pool.allocated', 0),\n",
       "             ('allocation.large_pool.current', 0),\n",
       "             ('allocation.large_pool.freed', 0),\n",
       "             ('allocation.large_pool.peak', 0),\n",
       "             ('allocation.small_pool.allocated', 60),\n",
       "             ('allocation.small_pool.current', 3),\n",
       "             ('allocation.small_pool.freed', 57),\n",
       "             ('allocation.small_pool.peak', 9),\n",
       "             ('inactive_split.all.allocated', 22),\n",
       "             ('inactive_split.all.current', 1),\n",
       "             ('inactive_split.all.freed', 21),\n",
       "             ('inactive_split.all.peak', 2),\n",
       "             ('inactive_split.large_pool.allocated', 0),\n",
       "             ('inactive_split.large_pool.current', 0),\n",
       "             ('inactive_split.large_pool.freed', 0),\n",
       "             ('inactive_split.large_pool.peak', 0),\n",
       "             ('inactive_split.small_pool.allocated', 22),\n",
       "             ('inactive_split.small_pool.current', 1),\n",
       "             ('inactive_split.small_pool.freed', 21),\n",
       "             ('inactive_split.small_pool.peak', 2),\n",
       "             ('inactive_split_bytes.all.allocated', 2128896),\n",
       "             ('inactive_split_bytes.all.current', 2095616),\n",
       "             ('inactive_split_bytes.all.freed', 33280),\n",
       "             ('inactive_split_bytes.all.peak', 2096640),\n",
       "             ('inactive_split_bytes.large_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.large_pool.current', 0),\n",
       "             ('inactive_split_bytes.large_pool.freed', 0),\n",
       "             ('inactive_split_bytes.large_pool.peak', 0),\n",
       "             ('inactive_split_bytes.small_pool.allocated', 2128896),\n",
       "             ('inactive_split_bytes.small_pool.current', 2095616),\n",
       "             ('inactive_split_bytes.small_pool.freed', 33280),\n",
       "             ('inactive_split_bytes.small_pool.peak', 2096640),\n",
       "             ('num_alloc_retries', 0),\n",
       "             ('num_ooms', 0),\n",
       "             ('reserved_bytes.all.allocated', 2097152),\n",
       "             ('reserved_bytes.all.current', 2097152),\n",
       "             ('reserved_bytes.all.freed', 0),\n",
       "             ('reserved_bytes.all.peak', 2097152),\n",
       "             ('reserved_bytes.large_pool.allocated', 0),\n",
       "             ('reserved_bytes.large_pool.current', 0),\n",
       "             ('reserved_bytes.large_pool.freed', 0),\n",
       "             ('reserved_bytes.large_pool.peak', 0),\n",
       "             ('reserved_bytes.small_pool.allocated', 2097152),\n",
       "             ('reserved_bytes.small_pool.current', 2097152),\n",
       "             ('reserved_bytes.small_pool.freed', 0),\n",
       "             ('reserved_bytes.small_pool.peak', 2097152),\n",
       "             ('segment.all.allocated', 1),\n",
       "             ('segment.all.current', 1),\n",
       "             ('segment.all.freed', 0),\n",
       "             ('segment.all.peak', 1),\n",
       "             ('segment.large_pool.allocated', 0),\n",
       "             ('segment.large_pool.current', 0),\n",
       "             ('segment.large_pool.freed', 0),\n",
       "             ('segment.large_pool.peak', 0),\n",
       "             ('segment.small_pool.allocated', 1),\n",
       "             ('segment.small_pool.current', 1),\n",
       "             ('segment.small_pool.freed', 0),\n",
       "             ('segment.small_pool.peak', 1)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
