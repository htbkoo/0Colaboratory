{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01f5f7d7297ff072cbcbd90f258bca87caa80ac8"
   },
   "source": [
    "**[Machine Learning Course Home Page](https://www.kaggle.com/learn/machine-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from learntools.core import *\n",
    "\n",
    "\n",
    "\n",
    "# Path of the file to read. We changed the directory structure to simplify submitting to a competition\n",
    "iowa_file_path = '../input/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e662c5f1617cabeb95d836bc14ada709d036bbd"
   },
   "source": [
    "# Creating a Model For the Competition\n",
    "\n",
    "Build a XGBoost model and train it on all of **X** and **y**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_X.values, train_y.values)\n",
    "dval = xgb.DMatrix(val_X.values)\n",
    "\n",
    "param = {'max_depth':3, 'eta':0.001, }\n",
    "num_round = 20000\n",
    "# bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "# make prediction\n",
    "# xgb_val_preds = bst.predict(dval)\n",
    "# rf_val_mae = mean_absolute_error(xgb_val_preds, val_y)\n",
    "\n",
    "# print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d43c2ebc134ac4f1fd020f44c81060ec8800102e"
   },
   "source": [
    "# Make Predictions\n",
    "Read the file of \"test\" data. And apply your model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Id   MSSubClass     ...            MoSold       YrSold\n",
      "count  1459.000000  1459.000000     ...       1459.000000  1459.000000\n",
      "mean   2190.000000    57.378341     ...          6.104181  2007.769705\n",
      "std     421.321334    42.746880     ...          2.722432     1.301740\n",
      "min    1461.000000    20.000000     ...          1.000000  2006.000000\n",
      "25%    1825.500000    20.000000     ...          4.000000  2007.000000\n",
      "50%    2190.000000    50.000000     ...          6.000000  2008.000000\n",
      "75%    2554.500000    70.000000     ...          8.000000  2009.000000\n",
      "max    2919.000000   190.000000     ...         12.000000  2010.000000\n",
      "\n",
      "[8 rows x 37 columns]\n",
      "['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n"
     ]
    }
   ],
   "source": [
    "# path to file you will use for predictions\n",
    "test_data_path = '../input/test.csv'\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "print(test_data.describe())\n",
    "print(features)\n",
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix(train_X.values, train_y.values)\n",
    "dtest = xgb.DMatrix(test_X.values)\n",
    "\n",
    "# specify parameters via map\n",
    "# param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "param = {'max_depth':3, 'eta':0.0001, }\n",
    "num_round = 200000\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                      'SalePrice': preds})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "output.to_csv('submission_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Work\n",
    "After filling in the code above:\n",
    "1. Click the **Commit and Run** button. \n",
    "2. After your code has finished running, click the small double brackets **<<** in the upper left of your screen.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "3. Go to the output tab at top of your screen. Select the button to submit your file to the competition.  \n",
    "4. If you want to keep working to improve your model, select the edit button. Then you can change your model and repeat the process.\n",
    "\n",
    "Congratulations, you've started competing in Machine Learning competitions.\n",
    "\n",
    "# Continuing Your Progress\n",
    "There are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n",
    "\n",
    "The best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n",
    "\n",
    "Level 2 of this course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n",
    "\n",
    "\n",
    "# Other Courses\n",
    "The **[Pandas course](https://kaggle.com/Learn/Pandas)** will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n",
    "\n",
    "You are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** course, where you will build models with better-than-human level performance at computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Machine Learning Course Home Page](https://www.kaggle.com/learn/machine-learning)**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
